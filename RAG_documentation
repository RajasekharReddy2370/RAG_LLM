RAG
https://www.youtube.com/watch?v=buTi1AarFDs


Retrieval Augmented Generation : Retrieval-Augmented Generation (RAG) is the process of optimizing the output of a large language model

There are several steps in RAG

1 . Cleaned Data send to Embedding Model

2 . Make Embeddings the cleaned Data Through Embeddings Model
Embeddings are numerical representations of data (text, images, audio, etc.) in a lower-dimensional vector space.
They are a way to convert complex, unstructured data into a structured form that machine learning models can process efficiently.

3 . Store the Embeddings in the Vector Database
A vector database is a type of database designed to store, index, and search high-dimensional vectors, which are mathematical representations of data points.
These vectors are typically generated by machine learning models and are used to represent unstructured data like text, images, videos, and audio.

Pinecone:
Cloud-native, fully managed, and optimized for real-time applications.

Weaviate:
Open-source, integrates well with machine learning pipelines, and supports hybrid search (structured + unstructured).

Milvus:
Open-source and highly scalable. Designed for large-scale vector search.

Vespa:
Focuses on combining structured and vector data for hybrid search.

Redis:
Offers vector similarity search as a module alongside traditional database functionalities.

After user generate prompt 
the RAG finds the nearest Embeddings in vector database and send to LLM[like openai,llama etc]
and optimise the output for understanding the user


